diff -ruN '--exclude=__pycache__' '--exclude=*.pyc' gbce_before/genostream/cli.py gbce_strict/genostream/cli.py
--- gbce_before/genostream/cli.py	2025-12-13 07:25:53.998251343 +0000
+++ gbce_strict/genostream/cli.py	2025-12-13 07:39:43.006849673 +0000
@@ -28,6 +28,22 @@
     v = getattr(args, "min_orf_aa", None)
     return int(v if v is not None else train_cfg.min_orf_aa)
 
+def _bool_opt(v, default: bool) -> bool:
+    return default if v is None else bool(v)
+
+
+def _get_protein_opts(args, train_cfg):
+    """Options used for aa+genbank CDS extraction and filtering."""
+    return {
+        "protein_strict_cds_only": _bool_opt(getattr(args, "strict_cds", None), getattr(train_cfg, "protein_strict_cds_only", False)),
+        "protein_require_translation": _bool_opt(getattr(args, "require_translation", None), getattr(train_cfg, "protein_require_translation", False)),
+        "protein_reject_partial": _bool_opt(getattr(args, "reject_partial_cds", None), getattr(train_cfg, "protein_reject_partial", True)),
+        "protein_require_start_m": _bool_opt(getattr(args, "require_start_m", None), getattr(train_cfg, "protein_require_start_m", True)),
+        "protein_x_free": _bool_opt(getattr(args, "x_free", None), getattr(train_cfg, "protein_x_free", True)),
+        "protein_min_aa": int(getattr(args, "min_protein_aa", None) if getattr(args, "min_protein_aa", None) is not None else getattr(train_cfg, "protein_min_aa", getattr(train_cfg, "min_orf_aa", 90))),
+        "protein_max_aa": int(getattr(args, "max_protein_aa", None) if getattr(args, "max_protein_aa", None) is not None else getattr(train_cfg, "protein_max_aa", 5000)),
+    }
+
 
 def _get_source(args, tok: str) -> str:
     v = getattr(args, "source", None)
@@ -121,19 +137,23 @@
     _validate_tok_params(tok, window_size, stride, frame)
 
     src = _get_source(args, tok)
+
+    protein_opts = _get_protein_opts(args, train_cfg) if (tok == 'aa' and src == 'genbank') else {}
     _ensure_record(args.accession, src, io_cfg=io_cfg, ncbi_cfg=ncbi_cfg, force=False)
 
     out_path = encoded_cache_path(
         io_cfg, args.accession, tok, window_size, stride, frame,
         source=src,
         min_orf_aa=(min_orf if tok=="aa" else None),
+        **protein_opts
     )
     encoded = encode_accession(
         args.accession, io_cfg, window_size, stride,
         tokenizer=tok, frame_offset=frame, min_orf_aa=min_orf,
         source=src,
-        save_to_disk=True, out_path=out_path
-    )
+        save_to_disk=True, out_path=out_path,
+            **protein_opts
+        )
     print(f"{args.accession}: encoded tokenizer={tok} source={src} -> shape={encoded.shape} saved={out_path}")
     return 0
 
@@ -152,6 +172,8 @@
 
     src = _get_source(args, tok)
 
+    protein_opts = _get_protein_opts(args, train_cfg) if (tok == 'aa' and src == 'genbank') else {}
+
     batch_size = args.batch_size or train_cfg.batch_size
     steps = args.steps or train_cfg.steps_per_plasmid
 
@@ -161,6 +183,7 @@
         io_cfg, args.accession, tok, window_size, stride, frame,
         source=src,
         min_orf_aa=(min_orf if tok=="aa" else None),
+        **protein_opts
     )
     if os.path.exists(enc_path) and not args.reencode:
         encoded = np.load(enc_path)
@@ -170,7 +193,8 @@
             args.accession, io_cfg, window_size, stride,
             tokenizer=tok, frame_offset=frame, min_orf_aa=min_orf,
             source=src,
-            save_to_disk=True, out_path=enc_path
+            save_to_disk=True, out_path=enc_path,
+            **protein_opts
         )
 
     last_total = train_on_encoded(
@@ -204,12 +228,15 @@
     _validate_tok_params(tok, window_size, stride, frame)
 
     src = _get_source(args, tok)
+
+    protein_opts = _get_protein_opts(args, train_cfg) if (tok == 'aa' and src == 'genbank') else {}
     _ensure_record(args.accession, src, io_cfg=io_cfg, ncbi_cfg=ncbi_cfg, force=False)
 
     enc_path = encoded_cache_path(
         io_cfg, args.accession, tok, window_size, stride, frame,
         source=src,
         min_orf_aa=(min_orf if tok=="aa" else None),
+        **protein_opts
     )
     if os.path.exists(enc_path) and not args.reencode:
         encoded = np.load(enc_path)
@@ -218,7 +245,8 @@
             args.accession, io_cfg, window_size, stride,
             tokenizer=tok, frame_offset=frame, min_orf_aa=min_orf,
             source=src,
-            save_to_disk=True, out_path=enc_path
+            save_to_disk=True, out_path=enc_path,
+            **protein_opts
         )
 
     errors = compute_window_errors(
@@ -258,6 +286,8 @@
     _validate_tok_params(tok, window_size, stride, frame)
 
     src = _get_source(args, tok)
+
+    protein_opts = _get_protein_opts(args, train_cfg) if (tok == 'aa' and src == 'genbank') else {}
     _ensure_record(args.accession, src, io_cfg=io_cfg, ncbi_cfg=ncbi_cfg, force=False)
 
     steps = args.steps or train_cfg.steps_per_plasmid
@@ -267,6 +297,7 @@
         io_cfg, args.accession, tok, window_size, stride, frame,
         source=src,
         min_orf_aa=(min_orf if tok=="aa" else None),
+        **protein_opts
     )
     if os.path.exists(enc_path) and not args.reencode:
         encoded = np.load(enc_path)
@@ -275,7 +306,8 @@
             args.accession, io_cfg, window_size, stride,
             tokenizer=tok, frame_offset=frame, min_orf_aa=min_orf,
             source=src,
-            save_to_disk=True, out_path=enc_path
+            save_to_disk=True, out_path=enc_path,
+            **protein_opts
         )
 
     metric = compute_gc_from_encoded(encoded, tokenizer=tok)
@@ -342,6 +374,8 @@
 
     src = _get_source(args, tok)
 
+    protein_opts = _get_protein_opts(args, train_cfg) if (tok == 'aa' and src == 'genbank') else {}
+
     batch_size = args.batch_size or train_cfg.batch_size
     steps_per_plasmid = args.steps_per_plasmid or train_cfg.steps_per_plasmid
     max_epochs = args.max_epochs or train_cfg.max_stream_epochs
@@ -362,6 +396,7 @@
                 io_cfg, acc, tok, window_size, stride, frame,
                 source=src,
                 min_orf_aa=(min_orf if tok=="aa" else None),
+                **protein_opts
             )
             if os.path.exists(enc_path):
                 encoded = np.load(enc_path)
@@ -370,8 +405,9 @@
                     acc, io_cfg, window_size, stride,
                     tokenizer=tok, frame_offset=frame, min_orf_aa=min_orf,
                     source=src,
-                    save_to_disk=True, out_path=enc_path
-                )
+                    save_to_disk=True, out_path=enc_path,
+                **protein_opts
+            )
 
             _ = train_on_encoded(
                 acc, encoded,
@@ -472,6 +508,20 @@
         sp.add_argument("--frame-offset", type=int, choices=[0,1,2], default=None, help="Codon frame offset (default from config)")
         sp.add_argument("--min-orf-aa", type=int, default=None, help="AA tokenizer: minimum ORF length in amino acids (default from config)")
         sp.add_argument("--source", choices=["fasta","genbank"], default=None, help="Sequence record source. Default: fasta for base/codon, genbank for aa.")
+        sp.add_argument("--strict-cds", action=argparse.BooleanOptionalAction, default=None,
+                        help="AA+GenBank: if enabled, require CDS proteins and DISABLE naive ORF fallback.")
+        sp.add_argument("--require-translation", action=argparse.BooleanOptionalAction, default=None,
+                        help="AA+GenBank: if enabled, only accept CDS entries with /translation qualifier.")
+        sp.add_argument("--reject-partial-cds", dest="reject_partial_cds", action=argparse.BooleanOptionalAction, default=None,
+                        help="AA+GenBank: reject CDS with partial endpoints (< or >) in location.")
+        sp.add_argument("--require-start-m", action=argparse.BooleanOptionalAction, default=None,
+                        help="AA+GenBank: require proteins start with 'M'.")
+        sp.add_argument("--x-free", action=argparse.BooleanOptionalAction, default=None,
+                        help="AA+GenBank: reject proteins containing 'X'.")
+        sp.add_argument("--min-protein-aa", dest="min_protein_aa", type=int, default=None,
+                        help="AA+GenBank: minimum protein length in aa (default from config).")
+        sp.add_argument("--max-protein-aa", dest="max_protein_aa", type=int, default=None,
+                        help="AA+GenBank: maximum protein length in aa (default from config).")
 
     def add_loss_args(sp):
         sp.add_argument(
diff -ruN '--exclude=__pycache__' '--exclude=*.pyc' gbce_before/genostream/config.py gbce_strict/genostream/config.py
--- gbce_before/genostream/config.py	2025-12-13 07:25:50.444356673 +0000
+++ gbce_strict/genostream/config.py	2025-12-13 07:29:51.857036645 +0000
@@ -31,6 +31,14 @@
         "protein_window_aa": 256,
         "protein_stride_aa": 128,
         "min_orf_aa": 90,
+        # biologically grounded GenBank/CDS options (aa + source=genbank)
+        "protein_strict_cds_only": False,       # no ORF fallback
+        "protein_require_translation": False,   # only accept /translation qualifiers
+        "protein_reject_partial": True,        # reject CDS with < or > in location
+        "protein_require_start_m": True,       # require protein begins with M
+        "protein_x_free": True,               # reject proteins containing X
+        "protein_min_aa": 90,                 # minimum protein length (aa)
+        "protein_max_aa": 5000,               # maximum protein length (aa)
     },
     "io": {
         "cache_fasta_dir": "cache/fasta",
@@ -71,6 +79,14 @@
     protein_stride_aa: int
     min_orf_aa: int
 
+    protein_strict_cds_only: bool
+    protein_require_translation: bool
+    protein_reject_partial: bool
+    protein_require_start_m: bool
+    protein_x_free: bool
+    protein_min_aa: int
+    protein_max_aa: int
+
 @dataclass
 class IOConfig:
     cache_fasta_dir: str
@@ -131,6 +147,13 @@
             protein_window_aa=int(t.get("protein_window_aa", 256)),
             protein_stride_aa=int(t.get("protein_stride_aa", 128)),
             min_orf_aa=int(t.get("min_orf_aa", 90)),
+            protein_strict_cds_only=bool(t.get("protein_strict_cds_only", False)),
+            protein_require_translation=bool(t.get("protein_require_translation", False)),
+            protein_reject_partial=bool(t.get("protein_reject_partial", True)),
+            protein_require_start_m=bool(t.get("protein_require_start_m", True)),
+            protein_x_free=bool(t.get("protein_x_free", True)),
+            protein_min_aa=int(t.get("protein_min_aa", t.get("min_orf_aa", 90))),
+            protein_max_aa=int(t.get("protein_max_aa", 5000)),
         ),
         IOConfig(
             cache_fasta_dir=io.get("cache_fasta_dir", "cache/fasta"),
diff -ruN '--exclude=__pycache__' '--exclude=*.pyc' gbce_before/genostream/encoding.py gbce_strict/genostream/encoding.py
--- gbce_before/genostream/encoding.py	2025-12-13 07:25:50.444670540 +0000
+++ gbce_strict/genostream/encoding.py	2025-12-13 07:37:08.711218102 +0000
@@ -226,146 +226,238 @@
         aas.append(CODON_TO_AA.get(cod, "X"))
     return "".join(aas)
 
-def extract_cds_proteins_from_genbank(path: str, min_aa: int = 90) -> List[str]:
-    """
-    Extract protein sequences from GenBank FEATURES/CDS.
+def extract_cds_proteins_from_genbank(
+    path: str,
+    min_aa: int = 90,
+    max_aa: int | None = None,
+    require_translation: bool = False,
+    reject_partial: bool = True,
+    require_start_m: bool = True,
+    x_free: bool = True,
+) -> tuple[list[str], dict[str, int]]:
+    """Extract proteins from a GenBank flatfile's CDS features.
+
+    This parser is purposely lightweight (no Biopython). It understands:
+      - FEATURES / CDS blocks
+      - /translation="..." qualifiers (possibly multiline)
+      - /codon_start=N qualifier
+      - complement(...) locations
+
+    If /translation is missing and require_translation=False, it will try to
+    translate from the ORIGIN DNA using the CDS location.
 
-    Preference order per CDS:
-      1) /translation="..." qualifier (most reliable)
-      2) location + ORIGIN DNA + /codon_start (fallback)
-
-    Notes:
-      - Skips CDS with /pseudo or /pseudogene.
-      - Handles common location forms: 123..456, complement(123..456), join(...), complement(join(...)).
+    Returns (proteins, stats) where stats is a dict of counters.
     """
-    if not os.path.exists(path):
-        raise FileNotFoundError(f"GenBank not found: {path}")
+    import re
+
+    # Local imports to avoid heavy dependencies
+    valid_set = set(AA_ALPHABET)  # 20 standard AAs
+
+    stats: dict[str, int] = {
+        "cds_total": 0,
+        "cds_pseudo": 0,
+        "cds_partial": 0,
+        "cds_no_translation": 0,
+        "cds_no_origin": 0,
+        "prot_from_translation": 0,
+        "prot_from_dna": 0,
+        "prot_kept": 0,
+        "prot_too_short": 0,
+        "prot_too_long": 0,
+        "prot_bad_start": 0,
+        "prot_has_x": 0,
+        "prot_invalid_chars": 0,
+        "prot_internal_stop": 0,
+    }
 
-    # Parse ORIGIN DNA once for fallback translation
     try:
         origin_dna = parse_genbank_dna(path)
     except Exception:
         origin_dna = ""
 
-    proteins: List[str] = []
+    proteins: list[str] = []
+
     in_features = False
     in_origin = False
 
-    cur_loc: Optional[str] = None
-    cur_translation: Optional[str] = None
+    cur_loc_raw: str | None = None
+    cur_translation: str | None = None
     cur_codon_start: int = 1
     cur_is_pseudo: bool = False
     reading_translation = False
-    trans_buf: List[str] = []
+    trans_buf: list[str] = []
+
+    def _normalize_prot(s: str) -> str:
+        # Remove all whitespace, uppercase.
+        s2 = "".join(s.split()).strip().upper()
+        # Strip surrounding quotes if any
+        if s2.startswith('"') and s2.endswith('"') and len(s2) >= 2:
+            s2 = s2[1:-1]
+        # Remove trailing stop marker
+        if s2.endswith('*'):
+            s2 = s2[:-1]
+        return s2
+
+    def _passes_filters(prot: str) -> bool:
+        if not prot:
+            return False
+        if '*' in prot:
+            stats["prot_internal_stop"] += 1
+            return False
+        L = len(prot)
+        if L < int(min_aa):
+            stats["prot_too_short"] += 1
+            return False
+        if max_aa is not None and L > int(max_aa):
+            stats["prot_too_long"] += 1
+            return False
+        if require_start_m and not prot.startswith('M'):
+            stats["prot_bad_start"] += 1
+            return False
+        if x_free and ('X' in prot):
+            stats["prot_has_x"] += 1
+            return False
+        for ch in prot:
+            if ch in valid_set:
+                continue
+            if (not x_free) and ch == 'X':
+                continue
+            stats["prot_invalid_chars"] += 1
+            return False
+        return True
+
+    def _flush_current() -> None:
+        nonlocal cur_loc_raw, cur_translation, cur_codon_start, cur_is_pseudo, reading_translation, trans_buf
 
-    def flush_cds():
-        nonlocal cur_loc, cur_translation, cur_codon_start, cur_is_pseudo, reading_translation, trans_buf
-        if cur_loc is None:
+        if cur_loc_raw is None:
             return
+        stats["cds_total"] += 1
+
+        loc_raw = cur_loc_raw
+
         if cur_is_pseudo:
-            # reset
-            cur_loc = None; cur_translation = None; cur_codon_start = 1; cur_is_pseudo = False
-            reading_translation = False; trans_buf = []
+            stats["cds_pseudo"] += 1
+            cur_loc_raw = None
+            cur_translation = None
+            reading_translation = False
+            trans_buf = []
+            return
+
+        if reject_partial and ('<' in loc_raw or '>' in loc_raw):
+            stats["cds_partial"] += 1
+            cur_loc_raw = None
+            cur_translation = None
+            reading_translation = False
+            trans_buf = []
             return
 
-        prot = ""
-        if cur_translation:
-            prot = cur_translation
-        elif origin_dna:
-            cds_dna = extract_dna_from_location(origin_dna, cur_loc)
-            if cds_dna:
-                prot = translate_cds(cds_dna, codon_start=cur_codon_start)
-
-        prot = prot.replace(" ", "").replace("\n", "").strip().upper()
-        # Remove trailing '*' if present
-        if prot.endswith("*"):
-            prot = prot[:-1]
-        if prot and len(prot) >= min_aa:
-            proteins.append(prot)
-
-        # reset
-        cur_loc = None; cur_translation = None; cur_codon_start = 1; cur_is_pseudo = False
-        reading_translation = False; trans_buf = []
+        prot: str | None = None
+
+        if cur_translation is not None:
+            prot = _normalize_prot(cur_translation)
+            stats["prot_from_translation"] += 1
+
+        if prot is None:
+            if require_translation:
+                stats["cds_no_translation"] += 1
+            else:
+                if not origin_dna:
+                    stats["cds_no_origin"] += 1
+                else:
+                    s, e, is_comp = _parse_loc_range(loc_raw)
+                    if s is not None and e is not None:
+                        cds_dna = origin_dna[s-1:e]
+                        if is_comp:
+                            cds_dna = reverse_complement(cds_dna)
+                        prot = translate_cds(cds_dna, codon_start=cur_codon_start)
+                        stats["prot_from_dna"] += 1
+
+        if prot is not None:
+            prot = _normalize_prot(prot)
+            if _passes_filters(prot):
+                proteins.append(prot)
+                stats["prot_kept"] += 1
+
+        cur_loc_raw = None
+        cur_translation = None
+        reading_translation = False
+        trans_buf = []
 
-    with open(path, "r", encoding="utf-8", errors="ignore") as f:
+    with open(path, 'r', encoding='utf-8', errors='ignore') as f:
         for line in f:
-            if line.startswith("FEATURES"):
+            if line.startswith('FEATURES'):
                 in_features = True
                 continue
-            if line.startswith("ORIGIN"):
+            if line.startswith('ORIGIN'):
                 in_origin = True
-                # end of FEATURES parsing
-                in_features = False
-                # flush any CDS we were building
-                if reading_translation and trans_buf:
-                    cur_translation = "".join(trans_buf)
-                flush_cds()
+                if in_features:
+                    _flush_current()
                 continue
             if in_origin:
-                # no need to parse further here
                 continue
             if not in_features:
                 continue
 
-            # New feature begins at column 6 (5 spaces) with a key
-            if line.startswith("     ") and len(line) > 5 and line[5] != " ":
-                # starting a new feature; flush previous CDS if any
-                if reading_translation and trans_buf:
-                    cur_translation = "".join(trans_buf)
-                flush_cds()
-
-                key = line[5:21].strip()
+            if line.startswith('     CDS'):
+                _flush_current()
                 loc = line[21:].strip()
-                if key == "CDS":
-                    cur_loc = loc
-                    cur_translation = None
-                    cur_codon_start = 1
-                    cur_is_pseudo = False
-                    reading_translation = False
-                    trans_buf = []
-                else:
-                    cur_loc = None
+                cur_loc_raw = loc
+                cur_translation = None
+                cur_codon_start = 1
+                cur_is_pseudo = False
+                reading_translation = False
+                trans_buf = []
                 continue
 
-            # Qualifiers: start around column 22 (21 spaces)
-            if cur_loc is not None and line.startswith("                     "):
+            if cur_loc_raw is not None and line.startswith('                     /'):
                 q = line.strip()
-
-                if reading_translation:
-                    # keep accumulating until closing quote
-                    if q.endswith('"'):
-                        trans_buf.append(q.rstrip('"'))
-                        cur_translation = "".join(trans_buf)
+                if q.startswith('/pseudo'):
+                    cur_is_pseudo = True
+                elif q.startswith('/codon_start='):
+                    m = re.search(r'/codon_start=(\d+)', q)
+                    if m:
+                        try:
+                            cur_codon_start = int(m.group(1))
+                        except Exception:
+                            cur_codon_start = 1
+                elif q.startswith('/translation='):
+                    # /translation may span multiple lines until closing quote
+                    reading_translation = True
+                    after = q[len('/translation='):]
+                    trans_buf = [after]
+                    if after.endswith('"') and after.count('"') >= 2:
                         reading_translation = False
+                        cur_translation = "".join(trans_buf)
                         trans_buf = []
-                    else:
-                        trans_buf.append(q)
-                    continue
-
-                if q.startswith("/pseudo") or q.startswith("/pseudogene"):
-                    cur_is_pseudo = True
-                    continue
-                if q.startswith("/codon_start="):
-                    try:
-                        cur_codon_start = int(q.split("=", 1)[1].strip().strip('"'))
-                    except Exception:
-                        cur_codon_start = 1
-                    continue
-                if q.startswith("/translation="):
-                    val = q.split("=", 1)[1].lstrip()
-                    # translation is quoted and can span lines
-                    if val.startswith('"'):
-                        val = val[1:]
-                    if val.endswith('"'):
-                        cur_translation = val.rstrip('"')
+                else:
+                    # any other qualifier ends translation capture
+                    if reading_translation:
+                        # translation continues only on non-qualifier lines
+                        pass
+
+            elif cur_loc_raw is not None and reading_translation:
+                # continuation lines for translation are indented but not qualifiers
+                if line.startswith('                     '):
+                    piece = line.strip()
+                    trans_buf.append(piece)
+                    joined = "".join(trans_buf)
+                    if '"' in joined and joined.strip().endswith('"'):
                         reading_translation = False
+                        cur_translation = joined
+                        trans_buf = []
+                else:
+                    # stop if indent breaks
+                    reading_translation = False
+                    if trans_buf:
+                        cur_translation = "".join(trans_buf)
                         trans_buf = []
-                    else:
-                        reading_translation = True
-                        trans_buf = [val]
-                    continue
 
-    return proteins
+    # flush at EOF
+    _flush_current()
+
+    return proteins, stats
+
+
 # -----------------------------
 # Base encoding
 # -----------------------------
@@ -560,6 +652,14 @@
     tokenizer: str = "base",
     frame_offset: int = 0,
     min_orf_aa: int = 90,
+    # GenBank/CDS-only proteome controls (apply when tokenizer=aa and source=genbank)
+    protein_strict_cds_only: bool = False,
+    protein_require_translation: bool = False,
+    protein_reject_partial: bool = True,
+    protein_require_start_m: bool = True,
+    protein_x_free: bool = True,
+    protein_min_aa: int | None = None,
+    protein_max_aa: int | None = None,
     source: str = "fasta",
     save_to_disk: bool = True,
     out_path: Optional[str] = None,
@@ -590,16 +690,42 @@
     elif tok == "aa":
         proteins: List[str] = []
         if src == "genbank" and gb_for_proteins is not None:
+            # Prefer GenBank CDS translations; optionally enforce strict CDS-only mode.
+            cds_min = int(protein_min_aa) if protein_min_aa is not None else int(min_orf_aa)
             try:
-                proteins = extract_cds_proteins_from_genbank(gb_for_proteins, min_aa=min_orf_aa)
-                if proteins:
-                    logging.info(f"{accession}: extracted CDS proteins from GenBank: {len(proteins)} (min_aa={min_orf_aa})")
-                else:
-                    logging.warning(f"{accession}: GenBank contained no CDS translations >= {min_orf_aa}aa; falling back to naive ORFs.")
+                proteins, stats = extract_cds_proteins_from_genbank(
+                    gb_for_proteins,
+                    min_aa=cds_min,
+                    max_aa=protein_max_aa,
+                    require_translation=bool(protein_require_translation),
+                    reject_partial=bool(protein_reject_partial),
+                    require_start_m=bool(protein_require_start_m),
+                    x_free=bool(protein_x_free),
+                )
+                logging.info(
+                    f"{accession}: GenBank CDS kept={stats.get('prot_kept',0)}/{stats.get('cds_total',0)} "
+                    f"(tr={stats.get('prot_from_translation',0)} dna={stats.get('prot_from_dna',0)} "
+                    f"pseudo={stats.get('cds_pseudo',0)} partial={stats.get('cds_partial',0)} no_tr={stats.get('cds_no_translation',0)}) "
+                    f"min={cds_min} max={protein_max_aa} filters: startM={protein_require_start_m} xfree={protein_x_free} "
+                    f"partial_reject={protein_reject_partial} require_translation={protein_require_translation}"
+                )
             except Exception as e:
+                if protein_strict_cds_only:
+                    raise
                 logging.warning(f"{accession}: failed to parse GenBank CDS ({e}); falling back to naive ORFs.")
                 proteins = []
+
+            if protein_strict_cds_only and not proteins:
+                raise ValueError(
+                    f"{accession}: strict CDS-only mode produced 0 proteins after filters. "
+                    f"Try relaxing filters (e.g., --no-x-free, --no-require-start-m, lower --min-protein-aa) or disable --strict-cds."
+                )
         if not proteins:
+            if src == "genbank" and bool(protein_strict_cds_only):
+                raise ValueError(
+                    f"{accession}: strict CDS-only mode produced 0 proteins (no ORF fallback). "
+                    "Disable --strict-cds or switch to --source fasta if you want naive ORF discovery."
+                )
             proteins = find_orfs_proteins(seq, min_orf_aa=min_orf_aa)
         encoded = encode_proteins_aa_windows(proteins, window_aa=window_size, stride_aa=stride)
         logging.info(
diff -ruN '--exclude=__pycache__' '--exclude=*.pyc' gbce_before/genostream/io_utils.py gbce_strict/genostream/io_utils.py
--- gbce_before/genostream/io_utils.py	2025-12-13 07:25:50.444858033 +0000
+++ gbce_strict/genostream/io_utils.py	2025-12-13 07:38:57.120196957 +0000
@@ -81,6 +81,13 @@
     frame_offset: int,
     source: str = "fasta",
     min_orf_aa: int | None = None,
+    protein_strict_cds_only: bool | None = None,
+    protein_require_translation: bool | None = None,
+    protein_reject_partial: bool | None = None,
+    protein_require_start_m: bool | None = None,
+    protein_x_free: bool | None = None,
+    protein_min_aa: int | None = None,
+    protein_max_aa: int | None = None,
 ) -> str:
     """
     Encoded cache file path that avoids mixing tokenizers / window params.
@@ -103,6 +110,21 @@
         tag += f".f{int(frame_offset)}"
     if tok == "aa" and min_orf_aa is not None:
         tag += f".min{int(min_orf_aa)}"
+    if tok == "aa" and src == "genbank":
+        if protein_min_aa is not None:
+            tag += f".pmin{int(protein_min_aa)}"
+        if protein_max_aa is not None:
+            tag += f".pmax{int(protein_max_aa)}"
+        if protein_strict_cds_only:
+            tag += ".cdsonly"
+        if protein_require_translation:
+            tag += ".tronly"
+        if protein_reject_partial:
+            tag += ".nopartial"
+        if protein_require_start_m:
+            tag += ".mstart"
+        if protein_x_free:
+            tag += ".x0"
     import os
     fname = f"{accession}.{tag}.npy"
     return os.path.join(io_cfg.cache_encoded_dir, fname)
diff -ruN '--exclude=__pycache__' '--exclude=*.pyc' gbce_before/stream_config.yaml gbce_strict/stream_config.yaml
--- gbce_before/stream_config.yaml	2025-12-13 07:25:50.445416368 +0000
+++ gbce_strict/stream_config.yaml	2025-12-13 07:40:38.307379103 +0000
@@ -17,6 +17,24 @@
   kl_warmup_steps: 5000
   max_grad_norm: 5.0
 
+  # tokenizer (base|codon|aa)
+  tokenizer: base
+  frame_offset: 0
+
+  # proteome (aa mode) windowing
+  protein_window_aa: 256
+  protein_stride_aa: 128
+  min_orf_aa: 90
+
+  # biologically grounded GenBank/CDS options (aa + source=genbank)
+  protein_strict_cds_only: false
+  protein_require_translation: false
+  protein_reject_partial: true
+  protein_require_start_m: true
+  protein_x_free: true
+  protein_min_aa: 90
+  protein_max_aa: 5000
+
 io:
   cache_fasta_dir: "cache/fasta"
   cache_genbank_dir: "cache/genbank"
